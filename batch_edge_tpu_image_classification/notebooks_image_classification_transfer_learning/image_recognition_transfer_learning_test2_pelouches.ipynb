{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_recognition_transfer_learning_test2_pelouches.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFkENQdq-I86"
      },
      "source": [
        "NGROK_URL='http://09c34350b9e4.ngrok.io'\n",
        "EXPERIMENT='pelouches'\n",
        "EPOCHS=50\n",
        "VERSION=1\n",
        "\n",
        "SAVE_PATH='saved_model'\n",
        "%mkdir saved_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4qGEV6K-VMC",
        "outputId": "cc150d41-8111-401f-936c-132c2b2c1c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh7fIM_Z-yiP",
        "outputId": "30b16f76-11ef-4f4b-eb6d-d336942e2a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile -a requirements.txt\n",
        "tensorflow==2.1.0\n",
        "tensorflow-hub==0.8.0\n",
        "matplotlib==3.3.1\n",
        "numpy==1.19.1\n",
        "mlflow==1.11.0\n",
        "seaborn==0.11.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGxR_qFs_I1Z",
        "outputId": "65598112-bd10-463f-ee3a-bc7c64e1d53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 38kB/s \n",
            "\u001b[?25hCollecting tensorflow-hub==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/9d/d5772f94e31431cdb56a8bb2c34d8839bb7d7621f2a5959f4ef43207d7ac/tensorflow_hub-0.8.0-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.6MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/a7/b6fa244fd8a8814ef9408c8a5a7e4ed0340e232a6f0ce2046b42e50672c0/matplotlib-3.3.1-cp36-cp36m-manylinux1_x86_64.whl (11.6MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6MB 25.2MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/9a/7d474ba0860a41f771c9523d8c4ea56b084840b5ca4092d96bdee8a3b684/numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 316kB/s \n",
            "\u001b[?25hCollecting mlflow==1.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/2d/7fa1f6e310ded489d943ea20cd7977a9867cb8d81b526d9c9460ce4a5b39/mlflow-1.11.0-py3-none-any.whl (13.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9MB 322kB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn==0.11.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.11.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (0.10.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (0.35.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (1.4.1)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 36.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->-r requirements.txt (line 1)) (3.3.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (2020.6.20)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.1->-r requirements.txt (line 3)) (7.0.0)\n",
            "Collecting alembic<=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 42.6MB/s \n",
            "\u001b[?25hCollecting docker>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/8c/8d42dbd83679483db207535f4fb02dc84325fa78b290f057694b057fcd21/docker-4.3.1-py2.py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from mlflow==1.11.0->-r requirements.txt (line 5)) (0.3.1)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.11.0->-r requirements.txt (line 5)) (2.23.0)\n",
            "Collecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/d7/b2b0672e0331567157adf9281f41ee731c412ee518ca5e6552c27fa73c91/GitPython-3.1.9-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlflow==1.11.0->-r requirements.txt (line 5)) (1.1.2)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/55/93927d225236d6936f6a818667a2bafb649b6cba784f579360ae2a12e77b/databricks-cli-0.12.2.tar.gz (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow==1.11.0->-r requirements.txt (line 5)) (1.1.2)\n",
            "Collecting azure-storage-blob>=12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/84/7e51b3e1156bcb89a20b9ec641d4fced4800aa79daac3a403898c32046be/azure_storage_blob-12.5.0-py2.py3-none-any.whl (326kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 44.8MB/s \n",
            "\u001b[?25hCollecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/fa/f54f5662e0eababf0c49e92fd94bf178888562c0e7b677c8941bbbcd1bd6/querystring_parser-1.2.4.tar.gz\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow==1.11.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow==1.11.0->-r requirements.txt (line 5)) (0.3)\n",
            "Collecting gunicorn; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.6MB/s \n",
            "\u001b[?25hCollecting prometheus-flask-exporter\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/d5/8a046d683c2cc084b6a502812827ede69b1064f95d93f94b83f809b21723/prometheus_flask_exporter-0.18.1.tar.gz\n",
            "Collecting gorilla\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/56/5a683944cbfc77e429c6f03c636ca50504a785f60ffae91ddd7f5f7bb520/gorilla-0.3.0-py2.py3-none-any.whl\n",
            "Collecting sqlalchemy<=1.3.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/47/35edeb0f86c0b44934c05d961c893e223ef27e79e1f53b5e6f14820ff553/SQLAlchemy-1.3.13.tar.gz (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.11.0->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow==1.11.0->-r requirements.txt (line 5)) (3.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (50.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->-r requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (3.2.2)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow==1.11.0->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow==1.11.0->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow==1.11.0->-r requirements.txt (line 5)) (2.10)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mlflow==1.11.0->-r requirements.txt (line 5)) (2018.9)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow==1.11.0->-r requirements.txt (line 5)) (0.8.7)\n",
            "Collecting tenacity>=6.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/05/ff089032442058bd3386f9cd991cd88ccac81dca1494d78751621ee35e62/tenacity-6.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow==1.11.0->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow==1.11.0->-r requirements.txt (line 5)) (2.11.2)\n",
            "Collecting msrest>=0.6.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/f5/9e315fe8cb985b0ce052b34bcb767883dc739f46fadb62f05a7e6d6eedbe/msrest-0.6.19-py2.py3-none-any.whl (84kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.3MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/62/30f6936941d87a5ed72efb24249437824f6b2c953901245b58c91fde2f27/cryptography-3.1.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 47.7MB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/fa/46974f4a7ad78b27e3eda8a573cc0c2508849f0d7d360b61c07cc5b46014/azure_core-1.8.2-py2.py3-none-any.whl (122kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus_client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow==1.11.0->-r requirements.txt (line 5)) (0.8.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic<=1.4.1->mlflow==1.11.0->-r requirements.txt (line 5)) (1.1.1)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Collecting isodate>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.0->mlflow==1.11.0->-r requirements.txt (line 5)) (1.14.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-storage-blob>=12.0->mlflow==1.11.0->-r requirements.txt (line 5)) (2.20)\n",
            "Building wheels for collected packages: gast, alembic, databricks-cli, querystring-parser, prometheus-flask-exporter, sqlalchemy\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=4a86e07c38419be020fdb3854e2b7322a62415d9ce5cba188cbfe9944d3ef0c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=92fcdb347c501d31b9401904382fa6a93415a9f5f5c7016c8c2fc4cd2358c2ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.12.2-cp36-none-any.whl size=101167 sha256=af2801cd249dfb300066ad5cb5d6f32a8cc2970b2c2a729b105821995e23837e\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/b1/90/ffec5dfcc04dcdeb91a2132c3c74404f33792f15d79a63bcfd\n",
            "  Building wheel for querystring-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for querystring-parser: filename=querystring_parser-1.2.4-cp36-none-any.whl size=7078 sha256=d3a4ab2f73edd374ec2e0d626a371ab7cf734e120ebf99bf48dced7e44335f70\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/41/34/23ebf5d1089a9aed847951e0ee375426eb4ad0a7079d88d41e\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-cp36-none-any.whl size=17157 sha256=d6a9361495d2c0a3e8b710e33989675abde5fb329665f2f60dec22ebd2bf60e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/1f/b8/66bd9bc3a9d6c6987ff6c4dfeb6f1fe97b5a0e5ed5849c0437\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.13-cp36-cp36m-linux_x86_64.whl size=1217124 sha256=3d386ba187d23056089576c68736c7c3c36d547299e2efc00ae7ba1bcfc5a681\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/35/98/4c9cb3fd63d21d5606b972dd70643769745adf60e622467b71\n",
            "Successfully built gast alembic databricks-cli querystring-parser prometheus-flask-exporter sqlalchemy\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, numpy, keras-applications, tensorflow-estimator, tensorboard, tensorflow, tensorflow-hub, matplotlib, sqlalchemy, Mako, python-editor, alembic, websocket-client, docker, smmap, gitdb, gitpython, tenacity, databricks-cli, isodate, msrest, cryptography, azure-core, azure-storage-blob, querystring-parser, gunicorn, prometheus-flask-exporter, gorilla, mlflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "  Found existing installation: tensorflow-hub 0.9.0\n",
            "    Uninstalling tensorflow-hub-0.9.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.9.0\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: SQLAlchemy 1.3.19\n",
            "    Uninstalling SQLAlchemy-1.3.19:\n",
            "      Successfully uninstalled SQLAlchemy-1.3.19\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.1 azure-core-1.8.2 azure-storage-blob-12.5.0 cryptography-3.1.1 databricks-cli-0.12.2 docker-4.3.1 gast-0.2.2 gitdb-4.0.5 gitpython-3.1.9 gorilla-0.3.0 gunicorn-20.0.4 isodate-0.6.0 keras-applications-1.0.8 matplotlib-3.3.1 mlflow-1.11.0 msrest-0.6.19 numpy-1.19.1 prometheus-flask-exporter-0.18.1 python-editor-1.0.4 querystring-parser-1.2.4 smmap-3.0.4 sqlalchemy-1.3.13 tenacity-6.2.0 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 tensorflow-hub-0.8.0 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyrwYaQL_K1o"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers, Sequential\n",
        "from tensorflow.compat.v1.keras import backend as K\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import numpy as np\n",
        "import mlflow \n",
        "import argparse\n",
        "import os \n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O3sKyhv_MV8"
      },
      "source": [
        "#To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YN06Wkb_NbN"
      },
      "source": [
        "train_root = \"/content/gdrive/My Drive/Colab Notebooks/datasets/pelouches/train\"\n",
        "test_root = \"/content/gdrive/My Drive/Colab Notebooks/datasets/pelouches/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-7Q1z_UAclG"
      },
      "source": [
        "#create a custom callback to visualize the training progress during every epoch.\n",
        "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    self.batch_losses = []\n",
        "    self.batch_acc = []\n",
        "    \n",
        "  def on_batch_end(self, batch, logs=None):\n",
        "    self.batch_losses.append(logs['loss'])\n",
        "    self.batch_acc.append(logs['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shh1wZuTAd6m",
        "outputId": "3e565e5e-8cb3-4900-b226-8c5ad6aa619e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Train code\n",
        "train_generator = ImageDataGenerator(rescale=1/255) \n",
        "test_generator = ImageDataGenerator(rescale=1/255) \n",
        "\n",
        "train_image_data = train_generator.flow_from_directory(str(train_root),target_size=(224,224))\n",
        "test_image_data = test_generator.flow_from_directory(str(test_root), target_size=(224,224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 40 images belonging to 2 classes.\n",
            "Found 10 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGdkJPj_Ae7h"
      },
      "source": [
        "feature_extractor_url = r\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMvJcY-WAgGS",
        "outputId": "f602a606-d1f6-44ba-a62f-2625447aff3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "IMAGE_SIZE = hub.get_expected_image_size(hub.Module(feature_extractor_url))\n",
        "IMAGE_SIZE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[224, 224]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82cVni_aAhUx",
        "outputId": "762c7ab2-79cd-4680-850f-ecab314f6b74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
        "                                   input_shape=IMAGE_SIZE+[3], \n",
        "                                   trainable=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YnUV2BxAjj-"
      },
      "source": [
        "model = Sequential([\n",
        "        feature_extractor_layer,\n",
        "        layers.Dense(train_image_data.num_classes, activation = \"softmax\")\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_keYHAMAkuE"
      },
      "source": [
        "#Mlflow settings\n",
        "#set MLflow server \n",
        "mlflow.set_tracking_uri(NGROK_URL)\n",
        "#Set experiment\n",
        "if mlflow.get_experiment_by_name(EXPERIMENT) != None:\n",
        "    exp_id = mlflow.set_experiment(EXPERIMENT)\n",
        "else: \n",
        "    exp_id = mlflow.create_experiment(EXPERIMENT)\n",
        "\n",
        "#Close active runs\n",
        "if mlflow.active_run():\n",
        "    mlflow.end_run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5LUn1LVAlnm"
      },
      "source": [
        "# initialize the TFHub module\n",
        "sess = K.get_session() \n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yuIE0CzAmsv"
      },
      "source": [
        "loss='categorical_crossentropy'\n",
        "\n",
        "model.compile(\n",
        "        optimizer = tf.train.AdamOptimizer(),\n",
        "        loss = loss,\n",
        "        metrics = ['accuracy']\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEEYdVPMAnhy"
      },
      "source": [
        "# Early stopping to stop the training if loss start to increase. It also avoids overvitting.\n",
        "es = EarlyStopping(patience=2,monitor=\"val_loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWlnDRwDAoc7"
      },
      "source": [
        "#use CallBacks to record accuracy and loss.\n",
        "batch_stats = CollectBatchStats()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZgHHz1aApQ5"
      },
      "source": [
        "def image_load(image_path):\n",
        "    loaded_image = image.load_img(image_path)\n",
        "    image_rel = pathlib.Path(image_path).relative_to(train_root)\n",
        "    print(image_rel)\n",
        "    return loaded_image\n",
        "\n",
        "def feature_extractor(x):\n",
        "  feature_extractor_module = hub.Module(feature_extractor_url)\n",
        "  return feature_extractor_module(x)\n",
        "\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluate the model with unseen and untrained data\n",
        "    :param model:\n",
        "    :return: results of probability\n",
        "    \"\"\"\n",
        "\n",
        "    return model.evaluate(x_test, y_test)\n",
        "\n",
        "def get_binary_loss(hist):\n",
        "    loss = hist.history['loss']\n",
        "    loss_val = loss[len(loss) - 1]\n",
        "    return loss_val\n",
        "\n",
        "def get_binary_acc(hist):\n",
        "    acc = hist.history['accuracy']\n",
        "    acc_value = acc[len(acc) - 1]\n",
        "\n",
        "    return acc_value\n",
        "\n",
        "def get_validation_loss(hist):\n",
        "    val_loss = hist.history['val_loss']\n",
        "    val_loss_value = val_loss[len(val_loss) - 1]\n",
        "\n",
        "    return val_loss_value\n",
        "\n",
        "def get_validation_acc(hist):\n",
        "    val_acc = hist.history['val_accuracy']\n",
        "    val_acc_value = val_acc[len(val_acc) - 1]\n",
        "\n",
        "    return val_acc_value\n",
        "\n",
        "\n",
        "def print_metrics(hist):\n",
        "\n",
        "    acc_value = get_binary_acc(hist)\n",
        "    loss_value = get_binary_loss(hist)\n",
        "\n",
        "    val_acc_value = get_validation_acc(hist)\n",
        "\n",
        "    val_loss_value = get_validation_loss(hist)\n",
        "\n",
        "    print(\"Final metrics: binary_loss:%6.4f\" % loss_value)\n",
        "    print(\"Final metrics: binary_accuracy=%6.4f\" % acc_value)\n",
        "    print(\"Final metrics: validation_binary_loss:%6.4f\" % val_loss_value)\n",
        "    print(\"Final metrics: validation_binary_accuracy:%6.4f\" % val_acc_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeHTrMcpAqYw",
        "outputId": "c2d9f273-4e13-4ea2-dedb-39f9cceb2c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "t = time.time()\n",
        "SAVE_PATH=os.path.join(SAVE_PATH, \"{}\".format(int(t)))\n",
        "\n",
        "with mlflow.start_run(run_id=None, experiment_id=exp_id, run_name=None, nested=False): \n",
        "\n",
        "      # fitting the model\n",
        "      history = model.fit((item for item in train_image_data), epochs=EPOCHS,\n",
        "              steps_per_epoch=21,\n",
        "              callbacks = [batch_stats, es],validation_data=test_image_data)\n",
        "\n",
        "      #mlflow autolog\n",
        "      #mlflow.tensorflow.autolog()\n",
        "\n",
        "      #Set tags\n",
        "      tags={}\n",
        "      tags['name']=EXPERIMENT\n",
        "      tags['version']=VERSION\n",
        "      mlflow.set_tags(tags)\n",
        "\n",
        "      #mlflow logging\n",
        "      # log parameters\n",
        "      #mlflow.log_param(\"hidden_layers\", args.hidden_layers)\n",
        "      #mlflow.log_param(\"output\", args.output)\n",
        "      mlflow.log_param(\"epochs\", EPOCHS)\n",
        "      mlflow.log_param(\"loss_function\", loss)\n",
        "      # log metrics\n",
        "      mlflow.log_metric(\"binary_loss\", get_binary_loss(history))\n",
        "      mlflow.log_metric(\"binary_acc\",  get_binary_acc(history))\n",
        "      mlflow.log_metric(\"validation_loss\", get_binary_loss(history))\n",
        "      mlflow.log_metric(\"validation_acc\", get_validation_acc(history))\n",
        "      #results=evaluate_model() #TODO\n",
        "      #mlflow.log_metric(\"average_loss\", results[0])\n",
        "      #mlflow.log_metric(\"average_acc\", results[1])\n",
        "      \n",
        "      #log model\n",
        "      #model.save(os.path.join(BASE_DIR, \"models\", \"{}.h5\".format(int(t)))) #HDF5 format\n",
        "      tf.saved_model.save(model, SAVE_PATH) #SavedModel format\n",
        "      #mlflow.tensorflow.log_model(model, 'model') #TODO fix\n",
        "      \n",
        "      # log artifacts (matplotlib images for loss/accuracy)\n",
        "      #mlflow.log_artifacts(image_dir)\n",
        "\n",
        "      #print labels\n",
        "      label_names = sorted(train_image_data.class_indices.items(), key=lambda pair:pair[1])\n",
        "      label_names = np.array([key.title() for key, value in label_names])\n",
        "      print(label_names)\n",
        "\n",
        "      mlflow.end_run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "20/21 [===========================>..] - ETA: 2s - loss: 0.2073 - accuracy: 0.9475Epoch 1/50\n",
            "21/21 [==============================] - 58s 3s/step - loss: 0.1999 - accuracy: 0.9514 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0220 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 862ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 902ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 870ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 904ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 862ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 907ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 871ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 901ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 879ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 912ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 875ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 906ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 867ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 904ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 875ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 901ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 872ms/step - loss: 9.8744e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 9.1950e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 907ms/step - loss: 9.1856e-04 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 8.3462e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 874ms/step - loss: 8.3173e-04 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 7.9247e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 909ms/step - loss: 7.8842e-04 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 7.4708e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 872ms/step - loss: 7.4499e-04 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 6.6562e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 908ms/step - loss: 6.6666e-04 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 6.1524e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 873ms/step - loss: 6.0513e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 6.0160e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 906ms/step - loss: 6.0377e-04 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 5.3396e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 880ms/step - loss: 5.3558e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 5.3285e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 903ms/step - loss: 5.3276e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 5.1578e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 866ms/step - loss: 5.1193e-04 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 4.7451e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 906ms/step - loss: 4.7367e-04 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 4.5543e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 868ms/step - loss: 4.4627e-04 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 4.4065e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 905ms/step - loss: 4.4015e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 4.1395e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 862ms/step - loss: 4.2093e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 4.0656e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 899ms/step - loss: 4.0602e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 3.5576e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 860ms/step - loss: 3.5451e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 3.7391e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 901ms/step - loss: 3.7248e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 3.2680e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 869ms/step - loss: 3.2896e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 3.3173e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 914ms/step - loss: 3.3143e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 3.0585e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 863ms/step - loss: 3.0379e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 3.0171e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 891ms/step - loss: 3.0014e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 2.9705e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 867ms/step - loss: 2.9584e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 2.8874e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 902ms/step - loss: 2.8638e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 2.7091e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 864ms/step - loss: 2.6877e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 2.6052e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 906ms/step - loss: 2.5998e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 2.4697e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 860ms/step - loss: 2.4845e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 2.4023e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 897ms/step - loss: 2.4044e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 2.3707e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 871ms/step - loss: 2.3593e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 2.2027e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 20s 944ms/step - loss: 2.2144e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 2.1055e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 876ms/step - loss: 2.1562e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 2.0427e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 19s 916ms/step - loss: 2.0362e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 2.1706e-04 - accuracy: 1.0000Epoch 1/50\n",
            "21/21 [==============================] - 18s 875ms/step - loss: 2.1883e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/1602777973/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/1602777973/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['Kitten' 'Rufy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz2BCUgcArV9",
        "outputId": "1a45d03c-a6f4-4ec7-806a-cacead509ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "%%bash -s $SAVE_PATH\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['keras_layer_input'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 224, 224, 3)\n",
            "      name: serving_default_keras_layer_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 2)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-15 16:22:36.934041: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2020-10-15 16:22:36.934166: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2020-10-15 16:22:36.934180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbuDnDy2As1H"
      },
      "source": [
        "import matplotlib.image as mpimg \n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "def show_img(image):\n",
        "  testim = mpimg.imread(image)\n",
        "  imshow(testim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpjZbEByAt3Y"
      },
      "source": [
        "#input data\n",
        "import cv2\n",
        "\n",
        "dim=tuple([224, 224])\n",
        "img_test='dataset/test/Orange/Orange_054.jpg'\n",
        "#show_img(img_test)\n",
        "\n",
        "#resize image\n",
        "img_test=cv2.imread(img_test)\n",
        "img_test=cv2.resize(img_test, dim, interpolation=cv2.INTER_AREA)\n",
        "print(img_test.shape)\n",
        "img_test = np.array(img_test).reshape(-1, 224, 224, 3)\n",
        "img_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHhRFZL0FJ58"
      },
      "source": [
        "#load model, see: https://medium.com/@jsflo.dev/saving-and-loading-a-tensorflow-model-using-the-savedmodel-api-17645576527\n",
        "with tf.Session(graph=tf.Graph()) as sess:\n",
        "    tf.saved_model.loader.load(sess, [\"serve\"], SAVE_PATH)\n",
        "    graph = tf.get_default_graph()\n",
        "    print(graph.get_operations())\n",
        "\n",
        "    input_tensor = graph.get_tensor_by_name(\"serving_default_keras_layer_input:0\")\n",
        "    output_tensor = graph.get_tensor_by_name(\"StatefulPartitionedCall:0\")\n",
        "    print(input_tensor)\n",
        "    print(output_tensor)\n",
        "\n",
        "    feed_dict ={input_tensor:img_test}\n",
        "\n",
        "    #test model on an image\n",
        "    prediction=sess.run(output_tensor,feed_dict)[0]\n",
        "    index=np.argmax(prediction, axis=0)\n",
        "    print(prediction)\n",
        "    print(label_names[index])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}