{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection_transfer_learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Ll8icG0QX9",
        "outputId": "660cb487-503f-42b4-ba4c-561e5d74a438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#This repo content all the dataset, the record and the config that were used in training a TensorFlow pedestrian detector model.\n",
        "!git clone https://github.com/Tourenathan-G5organisation/Pedestrian-Detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Pedestrian-Detection'...\n",
            "remote: Enumerating objects: 1935, done.\u001b[K\n",
            "remote: Total 1935 (delta 0), reused 0 (delta 0), pack-reused 1935\u001b[K\n",
            "Receiving objects: 100% (1935/1935), 151.00 MiB | 41.57 MiB/s, done.\n",
            "Resolving deltas: 100% (931/931), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LZnsVSK1gCr"
      },
      "source": [
        "Note: To create tfrecord files from these .csv files generated above, we need to update the generate_tfrecord.py "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZDyfhbJ1jUu"
      },
      "source": [
        "#create the tfrecords files by running the command below from model/research/object_detection directory\n",
        "python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=images/train.record\n",
        "python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=images/test.record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em6kiI_p2uXK",
        "outputId": "16c13089-d895-464b-cd7f-fc6181849328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#configure how training will work before move forward. \n",
        "#Create a folder called training in the model/research/object_detection directory. \n",
        "#This folder will contain our training config files necessary for this training.\n",
        "%cd Pedestrian-Detection/\n",
        "%mkdir -p training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Pedestrian-Detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVhtNxom3NcH",
        "outputId": "7ef553e8-4fb7-4c8a-b39d-5c0bcd6d9301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile -a labelmap.pbtxt\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'person'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing labelmap.pbtxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hezqeUM3dpK"
      },
      "source": [
        "There are two ways to customize a pretrained model:\n",
        "\n",
        "**Feature Extraction**: Use the representations learned by a previous network to extract meaningful features from new samples. You simply add a new classifier, which will be trained from scratch, on top of the pretrained model so that you can repurpose the feature maps learned previously for the dataset.\n",
        "\n",
        "You do not need to (re)train the entire model. The base convolutional network already contains features that are generically useful for classifying pictures. However, the final, classification part of the pretrained model is specific to the original classification task, and subsequently specific to the set of classes on which the model was trained.\n",
        "\n",
        "**Fine-Tuning**: Unfreeze a few of the top layers of a frozen model base and jointly train both the newly-added classifier layers and the last layers of the base model. This allows us to \"fine-tune\" the higher-order feature representations in the base model in order to make them more relevant for the specific task.\n",
        "\n",
        "Sources: [Tensorflow docs](https://www.tensorflow.org/tutorials/images/transfer_learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4heLb47P3xU6"
      },
      "source": [
        "For this task we’ll use **Single Shot Detector(SSD)** with **MobileNet** (model optimized for inference on mobile) pretrained on the **COCO dataset** called *ssd_mobilenet_v2_quantized_coco*. First, We will download and extract the latest checkpoint that’s been pre-trained on the COCO dataset. Run the command below from object_detection directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0yC72l93y9t",
        "outputId": "353793a5-b823-466c-90cd-1062afb6228b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "%mkdir -p Pedestrian-Detection/pretrained/\n",
        "%cd Pedestrian-Detection/pretrained/\n",
        "!curl -O http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz \n",
        "!tar xzf ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz\n",
        "%rm ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz\n",
        "%cd ../..\n",
        "%ls Pedestrian-Detection/pretrained"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'Pedestrian-Detection/pretrained /'\n",
            "/content\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  138M  100  138M    0     0   193M      0 --:--:-- --:--:-- --:--:--  193M\n",
            "tar (child): pretrained/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n",
            "rm: cannot remove 'pretrained/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz': No such file or directory\n",
            "/\n",
            "ls: cannot access 'Pedestrian-Detection/pretrained': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzqwEiDw8DUl"
      },
      "source": [
        "**Training configuration file**: we will use as config file *ssd_mobilenet_v2_quantized_300x300_coco.config* which can be found at sample/config folder in the object_detection folder.\n",
        "\n",
        "update the file as follows:\n",
        "\n",
        "* Line 9: change the number of classes:\n",
        "\n",
        "```\n",
        "num_classes: 1\n",
        "```\n",
        "\n",
        "* Line 156: Update fine_tune_checkpoint to the path of model.ckpt\n",
        "\n",
        "```\n",
        "fine_tune_checkpoint: \"/content/Pedestrian-Detection/pretrained/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt\"\n",
        "```\n",
        "\n",
        "* Line 175: Update the path of the train.record file\n",
        "\n",
        "```\n",
        "input_path: \"/content/Pedestrian-Detection/images/train*.record\"\n",
        "```\n",
        "\n",
        "* Line 177 & 192: update the path to the path of labelmap.pbtxt\n",
        "\n",
        "```\n",
        "label_map_path: \"/content/Pedestrian-Detection/training/labelmap.pbtxt\"\n",
        "```\n",
        "\n",
        "* Line 190: Update the path of the test.record file\n",
        "\n",
        "```\n",
        "input_path: \"/content/Pedestrian-Detection/images/test*.record\"\n",
        "```\n",
        "\n",
        "* Add the line below to the eval_config if you want to use the coco evaluation metrics\n",
        "\n",
        "```\n",
        "metrics_set: \"coco_detection_metrics\"\n",
        "```\n",
        "\n",
        "* Line 181: Update the number of examples to the number of images in your test directory.\n",
        "\n",
        "```\n",
        "num_examples: 235\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWiITHE-A1eM"
      },
      "source": [
        "**Note: use the `config_pipeline.py` script to update automatically**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkeAwNoaDRwg"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHf62qorA-mp"
      },
      "source": [
        "#To use  use COCO evaluation metrics to evaluate the accuracy of our model during training. So we installed COCO APIs as follows:\n",
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi/PythonAPI\n",
        "%cp -r pycocotools <path_to_tensorflow>/models/research/\n",
        "%cd ../.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymVybyhKDXVw",
        "outputId": "4ae56299-ffe1-4a99-bb7e-8e6534fcb5ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#To train the model:\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "%cp models/research/object_detection/legacy/train.py models/research/object_detection/\n",
        "!python models/research/object_detection/train.py --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_quantized_300x300_coco.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-28 16:45:03.626622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"models/research/object_detection/train.py\", line 51, in <module>\n",
            "    from object_detection.builders import dataset_builder\n",
            "ModuleNotFoundError: No module named 'object_detection'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5bK5l9ED3o6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}